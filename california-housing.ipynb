{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California housing\n",
    "(Adapted from: Geron, A. (2017). Hands-on machine learning with Scikit-Learn and TensorFlow. O'Reilly.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from *datasets/housing.csv* and print out some basic info about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"datasets/housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some missing values in attribute total_bedrooms: this line filters rows in \n",
    "# the housing DataFrame that contain any missing values.\n",
    "# isna() → identifies missing values.\n",
    "# any(axis=1) → checks if any column in a row has NaN.\n",
    "housing[housing.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(housing.head())\n",
    "print(housing.describe())\n",
    "print(housing.info())\n",
    "print()\n",
    "print(housing[\"ocean_proximity\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the histograms of the features in the data set.\n",
    "\n",
    "Save the image to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.hist(bins=50, figsize=(20,15))\n",
    "plt.savefig(\"housing_hist.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into a learning and test set in 70:30 ratio. Make the split stratified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(0, max(housing[\"median_house_value\"]), 50)\n",
    "# Save discretized Y values in a new array, broken down by the bins created above.\n",
    "mhv = np.digitize(housing[\"median_house_value\"], bins)\n",
    "# this is needed to make stratified train/test sets\n",
    "L, T = train_test_split(housing, test_size=0.2, random_state=42, stratify=mhv)\n",
    "print(\"Learning set size: {:d}\\nTest set size: {:d}\".format(len(L), len(T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)\n",
    "plt.savefig(\"housing_lat_lon.png\", bbox_inches='tight')\n",
    "\n",
    "L.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "       s=L[\"population\"]/100, label=\"population\",\n",
    "       c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = L.corr(numeric_only=True)\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "print(\"Computing correlations...\");\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\", \"housing_median_age\"];\n",
    "scatter_matrix(L[attributes], figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual feature construction\n",
    "'''\n",
    "L[\"rooms_per_household\"] = L[\"total_rooms\"] / L[\"households\"]\n",
    "L[\"bedrooms_per_room\"] = L[\"total_bedrooms\"] / L[\"total_rooms\"]\n",
    "L[\"population_per_household\"] = L[\"population\"] / L[\"households\"]\n",
    "corr_matrix = L.corr(numeric_only=True)\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)\n",
    "'''\n",
    "# Comment and restart kernel after this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the data for Machine Learning algorithms\n",
    "housing = L.drop(\"median_house_value\", axis=1) # drop labels for training set\n",
    "housing_labels = L[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms_ix, bedrooms_ix, population_ix, household_ix = [list(housing.columns).index(col) for col in (\"total_rooms\", \"total_bedrooms\", \"population\", \"households\")]\n",
    "\n",
    "def add_extra_features(X):\n",
    "    rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "    population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "    return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = FunctionTransformer(add_extra_features, validate=False)\n",
    "\n",
    "all_attributes = list(housing.columns)+[\"rooms_per_household\", \"population_per_household\"]\n",
    "housing_extra_attribs = attr_adder.fit_transform(housing.values)\n",
    "housing_extra_attribs = pd.DataFrame(\n",
    "    housing_extra_attribs,\n",
    "    columns = all_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', FunctionTransformer(add_extra_features, validate=False)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "print(\"Finishing data preparation...\")\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)\n",
    "print(\"{}\".format(housing_prepared.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import *\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "models = [LinearRegression(),\n",
    "          KNeighborsRegressor(n_neighbors=5),\n",
    "          DecisionTreeRegressor(random_state=42),\n",
    "          RandomForestRegressor(n_estimators=10, random_state=42),\n",
    "          LassoLars(alpha=.1),\n",
    "          Ridge(alpha=.5),\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Learning: fitting the models to data...\")\n",
    "for m in models:\n",
    "    m.fit(housing_prepared, housing_labels)\n",
    "print(\"_______________________________________\\n\")\n",
    "\n",
    "print(\"Evaluating the models on training set\")\n",
    "from sklearn.metrics import mean_squared_error\n",
    "for reg in models:\n",
    "    housing_predictions = reg.predict(housing_prepared)\n",
    "    rmse = np.sqrt(mean_squared_error(housing_labels, housing_predictions))\n",
    "    print(\"{:23s}: {:.3f}\".format(reg.__class__.__name__, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluating the models using internal cross-validation\")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for reg in models:\n",
    "    scores = cross_val_score(reg, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    rmse_scores = np.sqrt(-scores)\n",
    "    print(\"{:23s}: {:.3f}+-{:.3f}\".format(reg.__class__.__name__, rmse_scores.mean(), rmse_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fine tuning the models with internal cross-validation\")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "              {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "              {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "             ]\n",
    "grid_search = GridSearchCV(models[3], param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(housing_prepared, housing_labels)\n",
    "\n",
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "for i in sorted(zip(feature_importances, list(housing_extra_attribs)), reverse=True):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final testing...\")\n",
    "final_model = grid_search.best_estimator_\n",
    "X_test = T.drop(\"median_house_value\", axis=1)\n",
    "y_test = T[\"median_house_value\"].copy()\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, final_predictions))\n",
    "print(\"RMSE:{:10.2f}\".format(final_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
